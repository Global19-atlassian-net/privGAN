{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Notebook illustrating performance of a CNN classifier on MNIST dataset compared against generated data by simple GAN(simpGAN) and privGan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved. \n",
    "# Licensed under the MIT License.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Reshape, Dense, Dropout, Flatten, LeakyReLU, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from privacygan import privacy_gan as pg\n",
    "from privacygan.mnist import mnist_gan\n",
    "from classifier.cnn_classifier import CNNClassifier\n",
    "import warnings\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "#https://github.com/keras-team/keras/wiki/Keras-2.0-release-notes\n",
    "#https://stackoverflow.com/questions/60289143/migrating-code-to-tensorflow-2-0-gives-invalid-argument-error-default-maxpoolin\n",
    "tf.keras.backend.set_image_data_format(\"channels_last\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve train and test data from the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "X_test = (X_test.astype(np.float32) - 127.5)/127.5\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2])\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 97s 413ms/step - loss: 0.3100 - accuracy: 0.9041 - val_loss: 0.0741 - val_accuracy: 0.9764\n",
      "Test loss: 0.07409970462322235\n",
      "Test accuracy: 0.9764000177383423\n"
     ]
    }
   ],
   "source": [
    "# CNN model to classify MNIST dataset\n",
    "y_tr = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_t = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "x_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "x_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "\n",
    "classifier = CNNClassifier(NUM_CLASSES,(28,28,1))\n",
    "score = classifier.train(x_train,y_tr,256,1,x_test,y_t)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "r_0 = [score[0],score[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SimpGan generate synthetic images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epochs: 1\n",
      "Batch size: 256\n",
      "Batches per epoch: 23.13671875\n",
      "epoch = 1/1, d_loss=0.549, g_loss=0.753                                                                                                                    \n",
      "1\n",
      "Epochs: 1\n",
      "Batch size: 256\n",
      "Batches per epoch: 26.3359375\n",
      "epoch = 1/1, d_loss=0.566, g_loss=0.723                                                                                                                    \n",
      "2\n",
      "Epochs: 1\n",
      "Batch size: 256\n",
      "Batches per epoch: 23.2734375\n",
      "epoch = 1/1, d_loss=0.551, g_loss=0.748                                                                                                                    \n",
      "3\n",
      "Epochs: 1\n",
      "Batch size: 256\n",
      "Batches per epoch: 23.94921875\n",
      "epoch = 1/1, d_loss=0.554, g_loss=0.741                                                                                                                    \n",
      "4\n",
      "Epochs: 1\n",
      "Batch size: 256\n",
      "Batches per epoch: 22.8203125\n",
      "epoch = 1/1, d_loss=0.562, g_loss=0.731                                                                                                                    \n",
      "5\n",
      "Epochs: 1\n",
      "Batch size: 256\n",
      "Batches per epoch: 21.17578125\n",
      "epoch = 1/1, d_loss=0.557, g_loss=0.729                                                                                                                    \n",
      "6\n",
      "Epochs: 1\n",
      "Batch size: 256\n",
      "Batches per epoch: 23.1171875\n",
      "epoch = 1/1, d_loss=0.550, g_loss=0.746                                                                                                                    \n",
      "7\n",
      "Epochs: 1\n",
      "Batch size: 256\n",
      "Batches per epoch: 24.47265625\n",
      "epoch = 1/1, d_loss=0.546, g_loss=0.733                                                                                                                    \n",
      "8\n",
      "Epochs: 1\n",
      "Batch size: 256\n",
      "Batches per epoch: 22.85546875\n",
      "epoch = 1/1, d_loss=0.552, g_loss=0.745                                                                                                                    \n",
      "9\n",
      "Epochs: 1\n",
      "Batch size: 256\n",
      "Batches per epoch: 23.23828125\n",
      "epoch = 1/1, d_loss=0.560, g_loss=0.730                                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "#generate simple synthetic images of same size as X_train with same balance\n",
    "X_c = []\n",
    "y_c = []\n",
    "\n",
    "for i in range(NUM_CLASSES):\n",
    "    print(i)\n",
    "    In = np.where(y_train==i)\n",
    "    X = X_train[In]\n",
    "    tf.keras.backend.clear_session()\n",
    "    optim = Adam(lr=0.0002, beta_1=0.5)\n",
    "    gen = pg.MNIST_Generator(optim=optim)\n",
    "    dis = pg.MNIST_Discriminator(optim=optim)\n",
    "    \n",
    "    #learn generator per digit \n",
    "    (generator, _, _, _) = pg.SimpGAN(X, generator = gen, discriminator = dis, \n",
    "                                      optim = optim, \n",
    "                                      epochs = 1, batchSize = 256)\n",
    "    \n",
    "    noise = np.random.normal(0, 1, size=[len(X), 100])\n",
    "    X_c += [generator.predict(noise)]\n",
    "    y_c += [i]*len(X)\n",
    "    \n",
    "X_c = np.concatenate(X_c)    \n",
    "y_c = np.array(y_c)\n",
    "\n",
    "\n",
    "## Shuffle labels around\n",
    "arr = np.arange(len(X_c))\n",
    "np.random.shuffle(arr)\n",
    "X_c = X_c[arr]\n",
    "y_c = y_c[arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 100s 424ms/step - loss: 0.1483 - accuracy: 0.9529 - val_loss: 5.7761 - val_accuracy: 0.7131\n",
      "Test loss: 5.776065826416016\n",
      "Test accuracy: 0.713100016117096\n"
     ]
    }
   ],
   "source": [
    "# CNN model to classify SimpGan generated images\n",
    "y_tr = tf.keras.utils.to_categorical(y_c, NUM_CLASSES)\n",
    "y_t = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "\n",
    "\n",
    "x_train = X_c.reshape(X_c.shape[0], 28, 28, 1)\n",
    "x_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "classifier = CNNClassifier(NUM_CLASSES,(28,28,1))\n",
    "score = classifier.train(x_train,y_tr,256,1,x_test,y_t)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "r_1 = [score[0],score[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using privGan generate synthetic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "24/24 [==============================] - 2s 91ms/step - loss: 0.7663 - val_loss: 0.6843\n",
      "dp-Accuracy: 0.5537734256289043\n",
      "Epochs: 1\n",
      "Batch size: 256\n",
      "Batches per epoch: 11\n",
      "epoch = 0/1, batch = 10/11                                                                                                     \n",
      "dLosses = [0.44798338 0.43747817]\n",
      "dpLosses = 0.0\n",
      "gLosses = 2.780775850469416\n",
      "dp-Accuracy: 0.0\n",
      "1\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 0.7586 - val_loss: 0.6925\n",
      "dp-Accuracy: 0.519430436072382\n",
      "Epochs: 1\n",
      "Batch size: 256\n",
      "Batches per epoch: 13\n",
      "epoch = 0/1, batch = 12/13                                                                                                     \n",
      "dLosses = [0.45303324 0.45078788]\n",
      "dpLosses = 0.0\n",
      "gLosses = 2.801565463726337\n",
      "dp-Accuracy: 0.0\n",
      "2\n",
      "24/24 [==============================] - 2s 90ms/step - loss: 0.7784 - val_loss: 0.7062\n",
      "dp-Accuracy: 0.501007049345418\n",
      "Epochs: 1\n",
      "Batch size: 256\n",
      "Batches per epoch: 11\n",
      "epoch = 0/1, batch = 10/11                                                                                                     \n",
      "dLosses = [0.46052673 0.43441514]\n",
      "dpLosses = 0.0\n",
      "gLosses = 2.7825122529810127\n",
      "dp-Accuracy: 0.0\n",
      "3\n",
      "24/24 [==============================] - 2s 103ms/step - loss: 0.7762 - val_loss: 0.6815\n",
      "dp-Accuracy: 0.5773935736421465\n",
      "Epochs: 1\n",
      "Batch size: 256\n",
      "Batches per epoch: 11\n",
      "epoch = 0/1, batch = 10/11                                                                                                     \n",
      "dLosses = [0.4565365  0.43634495]\n",
      "dpLosses = 0.0\n",
      "gLosses = 2.8145016106692227\n",
      "dp-Accuracy: 0.0\n",
      "4\n",
      "23/23 [==============================] - 2s 101ms/step - loss: 0.7616 - val_loss: 0.6856\n",
      "dp-Accuracy: 0.5491270112975009\n",
      "Epochs: 1\n",
      "Batch size: 256\n",
      "Batches per epoch: 11\n",
      "epoch = 0/1, batch = 10/11                                                                                                     \n",
      "dLosses = [0.46001426 0.45068038]\n",
      "dpLosses = 0.0\n",
      "gLosses = 2.7603890028866855\n",
      "dp-Accuracy: 0.0\n",
      "5\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 0.7496 - val_loss: 0.6829\n",
      "dp-Accuracy: 0.5644714997232982\n",
      "Epochs: 1\n",
      "Batch size: 256\n",
      "Batches per epoch: 10\n",
      "epoch = 0/1, batch = 9/10                                                                                                     \n",
      "dLosses = [0.47150389 0.46797331]\n",
      "dpLosses = 0.0\n",
      "gLosses = 2.7136204719543455\n",
      "dp-Accuracy: 0.0\n",
      "6\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.7664 - val_loss: 0.6851\n",
      "dp-Accuracy: 0.5471443055086178\n",
      "Epochs: 1\n",
      "Batch size: 256\n",
      "Batches per epoch: 11\n",
      "epoch = 0/1, batch = 10/11                                                                                                     \n",
      "dLosses = [0.45043655 0.44046837]\n",
      "dpLosses = 0.0\n",
      "gLosses = 2.819689620624889\n",
      "dp-Accuracy: 0.0\n",
      "7\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 0.7566 - val_loss: 0.6924\n",
      "dp-Accuracy: 0.5198723064644852\n",
      "Epochs: 1\n",
      "Batch size: 256\n",
      "Batches per epoch: 12\n",
      "epoch = 0/1, batch = 11/12                                                                                                     \n",
      "dLosses = [0.43447817 0.44149873]\n",
      "dpLosses = 0.0\n",
      "gLosses = 2.814864218235016\n",
      "dp-Accuracy: 0.0\n",
      "8\n",
      "23/23 [==============================] - 2s 96ms/step - loss: 0.7466 - val_loss: 0.6817\n",
      "dp-Accuracy: 0.575286275850282\n",
      "Epochs: 1\n",
      "Batch size: 256\n",
      "Batches per epoch: 11\n",
      "epoch = 0/1, batch = 10/11                                                                                                     \n",
      "dLosses = [0.44645918 0.44097685]\n",
      "dpLosses = 0.0\n",
      "gLosses = 2.7588589408180932\n",
      "dp-Accuracy: 0.0\n",
      "9\n",
      "24/24 [==============================] - 2s 92ms/step - loss: 0.7858 - val_loss: 0.6872\n",
      "dp-Accuracy: 0.5434526811228778\n",
      "Epochs: 1\n",
      "Batch size: 256\n",
      "Batches per epoch: 11\n",
      "epoch = 0/1, batch = 10/11                                                                                                     \n",
      "dLosses = [0.44989129 0.4480984 ]\n",
      "dpLosses = 0.0\n",
      "gLosses = 2.779847665266557\n",
      "dp-Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "#generate simple synthetic images of same size as X_train with same balance with privGan\n",
    "X_c2 = []\n",
    "y_c2 = []\n",
    "\n",
    "for i in range(NUM_CLASSES):\n",
    "    print(i)\n",
    "    In = np.where(y_train==i)\n",
    "    X = X_train[In]\n",
    "    tf.keras.backend.clear_session()\n",
    "    optim = Adam(lr=0.0002, beta_1=0.5)\n",
    "    generators = [mnist_gan.MNIST_Generator(optim = Adam(lr=0.0002, beta_1=0.5)),\n",
    "                  mnist_gan.MNIST_Generator(optim = Adam(lr=0.0002, beta_1=0.5))]\n",
    "    discriminators = [mnist_gan.MNIST_Discriminator(optim = Adam(lr=0.0002, beta_1=0.5))\n",
    "                      ,mnist_gan.MNIST_Discriminator(optim = Adam(lr=0.0002, beta_1=0.5))]\n",
    "    pDisc = mnist_gan.MNIST_DiscriminatorPrivate(OutSize = 2, \n",
    "                                          optim = Adam(lr=0.0002, beta_1=0.5))\n",
    "    \n",
    "    (generators, _, _, _, _, _)= pg.privGAN(X, epochs = 1, \n",
    "                                                                               disc_epochs=1,\n",
    "                                                                               batchSize=256,\n",
    "                                                                               generators = generators, \n",
    "                                                                               discriminators = discriminators,\n",
    "                                                                               pDisc = pDisc,\n",
    "                                                                               optim = optim,\n",
    "                                                                               privacy_ratio = 1.0)    \n",
    "    \n",
    "    noise1 = np.random.normal(0, 1, size=[len(X)//2, 100])\n",
    "    noise2 = np.random.normal(0, 1, size=[len(X)//2, 100])\n",
    "    X_c2 += [generators[0].predict(noise1)]\n",
    "    X_c2 += [generators[1].predict(noise2)]\n",
    "    y_c2 += [i]*(len(noise1) + len(noise2))\n",
    "    \n",
    "X_c2 = np.concatenate(X_c2)    \n",
    "y_c2 = np.array(y_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffle labels around\n",
    "arr = np.arange(len(X_c2))\n",
    "np.random.shuffle(arr)\n",
    "X_c2 = X_c2[arr]\n",
    "y_c2 = y_c2[arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 99s 420ms/step - loss: 0.2608 - accuracy: 0.9241 - val_loss: 25.0063 - val_accuracy: 0.3319\n",
      "Test loss: 25.006332397460938\n",
      "Test accuracy: 0.3319000005722046\n"
     ]
    }
   ],
   "source": [
    "#train CNN model for images created by privGan\n",
    "y_tr = tf.keras.utils.to_categorical(y_c2, NUM_CLASSES)\n",
    "y_t = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "x_train = X_c2.reshape(X_c2.shape[0], 28, 28, 1)\n",
    "x_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "\n",
    "\n",
    "classifier = CNNClassifier(NUM_CLASSES,(28,28,1))\n",
    "score = classifier.train(x_train,y_tr,256,1,x_test,y_t)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "r_2 = [score[0],score[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([0,1,2],[r_0[1],r_1[1],r_2[1]])\n",
    "plt.xticks([0,1,2],['Real','GAN','privGAN (1.0)'], rotation=45)\n",
    "plt.ylabel('Accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
